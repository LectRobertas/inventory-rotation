{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed0f1c8-a323-4b58-b5e3-6169275dfbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## InventoryRotationEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "572edc1e-39a4-4128-b4dc-21b08bfd93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a7c3f07-2dbd-4fec-8494-4348358277a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    1. DATA SELECTION\n",
    "\"\"\"\n",
    "# Path to the data (folders)\n",
    "path = ['C:/Users/Win-10/Documents/Python Scripts/ku']\n",
    "\n",
    "frames = []\n",
    "for p in path:\n",
    "    all_files = glob.glob(p + \"/history_*.csv\")\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, header=0, sep=',', index_col=None, low_memory=False)\n",
    "        frames.append(df)\n",
    "\n",
    "df_history = pd.concat(frames)\n",
    "\n",
    "df_items = pd.read_csv(p + \"/skus.csv\", header=0, sep=',', index_col=None, low_memory=False)\n",
    "df_locations = pd.read_csv(p + \"/locations.csv\", header=0, sep=',', index_col=None, low_memory=False)\n",
    "df_promotions = pd.read_csv(p + \"/promotions.csv\", header=0, sep=',', index_col=None, low_memory=False)\n",
    "\n",
    "# Remove temp variables from workspace\n",
    "del path, all_files, frames, filename, p, df\n",
    "    \n",
    "# Step 1: Filter df_items by multiple skuName values\n",
    "sku_names_to_filter = ['Dieninis kremas'] # ['Kūno apsauginis kremas','Lūpų dažai','Parfumuotas vanduo (EDP)','Kreminė pudra','Dieninis kremas','Lūpų blizgesiai','Akių šešėliai mono 1sp.','Tualetinis vanduo (EDT)']  # Example skuNames to filter by\n",
    "df_items = df_items[df_items['categoryGroup'].isin(sku_names_to_filter)]\n",
    "\n",
    "# Step 2: Filter df_history by the skuid values of the filtered df_items\n",
    "df_history = df_history[df_history['skuID'].isin(df_items['skuid'])]\n",
    "\n",
    "# Step 3: Filter data by the locations\n",
    "df_locations = df_locations[df_locations['slid'].isin([262,238])]\n",
    "df_history = df_history[df_history['slid'].isin([262,238])]\n",
    "df_history = df_history[(df_history['atSiteQnt'] > 0) | (df_history['consumption'] > 0)]\n",
    "\n",
    "# Set in chronological order\n",
    "df_history['updateDate'] = pd.to_datetime(df_history['updateDate'])\n",
    "df_history = df_history.sort_values(by='updateDate').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "009fdefa-13ed-483e-b230-c850a2c7f044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71918, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebc1820b-4a97-4d49-b3ad-433936e3be31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slid</th>\n",
       "      <th>skuID</th>\n",
       "      <th>updateDate</th>\n",
       "      <th>atSiteQnt</th>\n",
       "      <th>consumption</th>\n",
       "      <th>purchasingPrice</th>\n",
       "      <th>salesPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>71918.000000</td>\n",
       "      <td>71918.000000</td>\n",
       "      <td>71918</td>\n",
       "      <td>71918.000000</td>\n",
       "      <td>71918.000000</td>\n",
       "      <td>71918.000000</td>\n",
       "      <td>71918.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>254.999694</td>\n",
       "      <td>30499.587892</td>\n",
       "      <td>2024-01-03 07:59:24.359408896</td>\n",
       "      <td>123.851289</td>\n",
       "      <td>0.700159</td>\n",
       "      <td>25.338845</td>\n",
       "      <td>53.140266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>238.000000</td>\n",
       "      <td>533.000000</td>\n",
       "      <td>2022-09-27 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>238.000000</td>\n",
       "      <td>23743.000000</td>\n",
       "      <td>2023-09-06 00:00:00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.560000</td>\n",
       "      <td>23.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>262.000000</td>\n",
       "      <td>33030.000000</td>\n",
       "      <td>2024-01-12 00:00:00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.020000</td>\n",
       "      <td>43.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>262.000000</td>\n",
       "      <td>38118.000000</td>\n",
       "      <td>2024-05-24 00:00:00</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.305000</td>\n",
       "      <td>74.380200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>262.000000</td>\n",
       "      <td>54142.000000</td>\n",
       "      <td>2024-10-02 00:00:00</td>\n",
       "      <td>13656.000000</td>\n",
       "      <td>1415.000000</td>\n",
       "      <td>284.711000</td>\n",
       "      <td>438.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.908928</td>\n",
       "      <td>12209.926220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>731.927536</td>\n",
       "      <td>9.800807</td>\n",
       "      <td>21.292089</td>\n",
       "      <td>36.930782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               slid         skuID                     updateDate   \n",
       "count  71918.000000  71918.000000                          71918  \\\n",
       "mean     254.999694  30499.587892  2024-01-03 07:59:24.359408896   \n",
       "min      238.000000    533.000000            2022-09-27 00:00:00   \n",
       "25%      238.000000  23743.000000            2023-09-06 00:00:00   \n",
       "50%      262.000000  33030.000000            2024-01-12 00:00:00   \n",
       "75%      262.000000  38118.000000            2024-05-24 00:00:00   \n",
       "max      262.000000  54142.000000            2024-10-02 00:00:00   \n",
       "std       10.908928  12209.926220                            NaN   \n",
       "\n",
       "          atSiteQnt   consumption  purchasingPrice    salesPrice  \n",
       "count  71918.000000  71918.000000     71918.000000  71918.000000  \n",
       "mean     123.851289      0.700159        25.338845     53.140266  \n",
       "min        0.000000      0.000000         0.010000      0.000100  \n",
       "25%        2.000000      0.000000         7.560000     23.950000  \n",
       "50%        2.000000      0.000000        21.020000     43.760300  \n",
       "75%       10.000000      0.000000        35.305000     74.380200  \n",
       "max    13656.000000   1415.000000       284.711000    438.016500  \n",
       "std      731.927536      9.800807        21.292089     36.930782  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history.describe()  # 71_918 -> 10_584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58b54e9f-e0d5-4529-bc82-f844e52c1ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71918 entries, 0 to 71917\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   slid             71918 non-null  int64         \n",
      " 1   skuID            71918 non-null  int64         \n",
      " 2   updateDate       71918 non-null  datetime64[ns]\n",
      " 3   atSiteQnt        71918 non-null  float64       \n",
      " 4   consumption      71918 non-null  float64       \n",
      " 5   purchasingPrice  71918 non-null  float64       \n",
      " 6   salesPrice       71918 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(2)\n",
      "memory usage: 3.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_history.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c4ffaa2-8a29-4f32-a123-154794644267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slid</th>\n",
       "      <th>skuID</th>\n",
       "      <th>updateDate</th>\n",
       "      <th>atSiteQnt</th>\n",
       "      <th>consumption</th>\n",
       "      <th>purchasingPrice</th>\n",
       "      <th>salesPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33881</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34038</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34180</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34307</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34425</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       slid  skuID updateDate  atSiteQnt  consumption  purchasingPrice   \n",
       "33881   262  48722 2023-12-29       42.0          0.0             3.96  \\\n",
       "34038   262  48722 2023-12-30       42.0          0.0             3.96   \n",
       "34180   262  48722 2023-12-31       42.0          0.0             3.96   \n",
       "34307   262  48722 2024-01-01       42.0          0.0             3.96   \n",
       "34425   262  48722 2024-01-02       42.0          0.0             3.96   \n",
       "\n",
       "       salesPrice  \n",
       "33881     20.6198  \n",
       "34038     20.6198  \n",
       "34180     20.6198  \n",
       "34307     20.6198  \n",
       "34425     20.6198  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df_history[df_history['skuID'] == 48722]\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b70ef041-e6c9-452d-b3de-799ba28ecc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = temp.copy()\n",
    "\n",
    "# Convert updateDate to datetime and sort by time\n",
    "df['updateDate'] = pd.to_datetime(df['updateDate'])\n",
    "df = df.sort_values(by='updateDate').reset_index(drop=True)\n",
    "\n",
    "# Extract year and week number\n",
    "df['year'] = df['updateDate'].dt.year\n",
    "df['week'] = df['updateDate'].dt.isocalendar().week\n",
    "\n",
    "# Sort data by date to get the correct start and end of the week\n",
    "df = df.sort_values(by=['slid', 'skuID', 'year', 'week', 'updateDate'])\n",
    "\n",
    "# Group by location, SKU, year, and week\n",
    "weekly_summary = df.groupby(['slid', 'skuID', 'year', 'week']).agg({\n",
    "    'consumption': 'sum',                         # Total weekly consumption\n",
    "    'purchasingPrice': 'mean',                    # Average purchasing price\n",
    "    'salesPrice': 'mean',                         # Average sales price\n",
    "    #'isNewItem': 'max'                            # If any day has True, week should be True\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "# Step 1: Compute absolute week number (ensuring correct weekly progression)\n",
    "weekly_summary = weekly_summary.sort_values(by=['slid', 'skuID', 'year', 'week']).reset_index(drop=True)\n",
    "weekly_summary['absolute_week'] = (weekly_summary['year'] - weekly_summary['year'].min()) * 52 + weekly_summary['week']\n",
    "# Step 2: Find the first absolute week an item appeared in a location\n",
    "weekly_summary['first_absolute_week'] = weekly_summary.groupby(['slid', 'skuID'])['absolute_week'].transform('min')\n",
    "# Step 3: Compute remaining lock period (12-week lock from first appearance)\n",
    "weekly_summary['lockWeeksRemaining'] = (12 - (weekly_summary['absolute_week'] - weekly_summary['first_absolute_week'])).clip(lower=0)\n",
    "# Step 4: Drop unnecessary columns if needed\n",
    "weekly_summary.drop(columns=['first_absolute_week','absolute_week'], inplace=True)\n",
    "\n",
    "\n",
    "# Get the stock at the start and end of the week\n",
    "stock_start = df.groupby(['slid', 'skuID', 'year', 'week']).first().reset_index()[['slid', 'skuID', 'year', 'week', 'atSiteQnt']]\n",
    "stock_end = df.groupby(['slid', 'skuID', 'year', 'week']).last().reset_index()[['slid', 'skuID', 'year', 'week', 'atSiteQnt']]\n",
    "\n",
    "# Rename columns for clarity\n",
    "stock_start.rename(columns={'atSiteQnt': 'stock_start_week'}, inplace=True)\n",
    "stock_end.rename(columns={'atSiteQnt': 'stock_end_week'}, inplace=True)\n",
    "\n",
    "# Merge start and end stock with the weekly summary\n",
    "weekly_summary = weekly_summary.merge(stock_start, on=['slid', 'skuID', 'year', 'week'])\n",
    "weekly_summary = weekly_summary.merge(stock_end, on=['slid', 'skuID', 'year', 'week'])\n",
    "\n",
    "temp = weekly_summary.copy()\n",
    "\n",
    "\n",
    "# Filter out rows where stock_end_week is zero\n",
    "df_non_zero_stock = temp[(temp['stock_end_week'] > 0) | (temp['consumption'] > 0)]\n",
    "\n",
    "# Group by location, year, and week to count unique skuID\n",
    "unique_items_count = df_non_zero_stock.groupby(['slid', 'year', 'week'])['skuID'].nunique().reset_index()\n",
    "unique_items_count.rename(columns={'skuID': 'unique_items_count'}, inplace=True)\n",
    "\n",
    "# Merge the unique items count with the original DataFrame\n",
    "temp = temp.merge(unique_items_count, on=['slid', 'year', 'week'], how='left')\n",
    "\n",
    "# Fill NaN values with 0 (in case there are weeks with no items)\n",
    "temp['unique_items_count'] = temp['unique_items_count'].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "del stock_start, stock_end, weekly_summary, df, df_non_zero_stock, unique_items_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da8f679b-f367-4b1c-933a-b3a97cddf5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slid</th>\n",
       "      <th>skuID</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>consumption</th>\n",
       "      <th>purchasingPrice</th>\n",
       "      <th>salesPrice</th>\n",
       "      <th>lockWeeksRemaining</th>\n",
       "      <th>stock_start_week</th>\n",
       "      <th>stock_end_week</th>\n",
       "      <th>unique_items_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2023</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "      <td>12</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "      <td>11</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "      <td>10</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "      <td>9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "      <td>8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   slid  skuID  year  week  consumption  purchasingPrice  salesPrice   \n",
       "0   262  48722  2023    52          0.0             3.96     20.6198  \\\n",
       "1   262  48722  2024     1          5.0             3.96     20.6198   \n",
       "2   262  48722  2024     2          7.0             3.96     20.6198   \n",
       "3   262  48722  2024     3          6.0             3.96     20.6198   \n",
       "4   262  48722  2024     4          7.0             3.96     20.6198   \n",
       "\n",
       "   lockWeeksRemaining  stock_start_week  stock_end_week  unique_items_count  \n",
       "0                  12              42.0            42.0                   1  \n",
       "1                  11              42.0            37.0                   1  \n",
       "2                  10              32.0            31.0                   1  \n",
       "3                   9              30.0            25.0                   1  \n",
       "4                   8              15.0             8.0                   1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "929a67cf-287f-44d9-950e-07001deb8105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2023, 52],\n",
       " [2024, 1],\n",
       " [2024, 2],\n",
       " [2024, 3],\n",
       " [2024, 4],\n",
       " [2024, 5],\n",
       " [2024, 6],\n",
       " [2024, 18],\n",
       " [2024, 19],\n",
       " [2024, 20],\n",
       " [2024, 21],\n",
       " [2024, 22],\n",
       " [2024, 23],\n",
       " [2024, 24],\n",
       " [2024, 25],\n",
       " [2024, 26],\n",
       " [2024, 27],\n",
       " [2024, 28],\n",
       " [2024, 29],\n",
       " [2024, 30],\n",
       " [2024, 31],\n",
       " [2024, 32],\n",
       " [2024, 37],\n",
       " [2024, 38],\n",
       " [2024, 39],\n",
       " [2024, 40]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(temp[['year', 'week']].drop_duplicates().values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3f309-80e8-438b-8ef0-9d1d4882fa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "class InventoryRotationEnv(gym.Env):\n",
    "    def __init__(self, df_items, df_history, df_locations):\n",
    "        super(InventoryRotationEnv, self).__init__()\n",
    "\n",
    "        # Store dataset references\n",
    "        self.df_items = df_items\n",
    "        self.df_history = df_history\n",
    "        self.df_locations = df_locations\n",
    "        \n",
    "        # Define SKU & location count\n",
    "        self.num_skus = len(df_items)\n",
    "        self.num_locations = len(df_locations)\n",
    "\n",
    "        # Define action space (flattened MultiBinary)\n",
    "        self.action_space = spaces.MultiBinary(self.num_skus * self.num_locations)  # spaces.Box\n",
    "\n",
    "        # Define observation space (features per SKU-location pair)\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'current_stock_state': spaces.MultiBinary((self.num_skus, self.num_locations)),\n",
    "            'delta_margin': spaces.Box(low=-np.inf, high=np.inf, shape=(self.num_skus, self.num_locations), dtype=np.float32),\n",
    "            'delta_stock': spaces.Box(low=-np.inf, high=np.inf, shape=(self.num_skus, self.num_locations), dtype=np.float32),\n",
    "            'delta_profit': spaces.Box(low=-np.inf, high=np.inf, shape=(self.num_skus, self.num_locations), dtype=np.float32),\n",
    "            'week': spaces.Box(low=1, high=53, shape=(self.num_skus, self.num_locations), dtype=np.int16),\n",
    "            'unique_items_count': spaces.Box(low=0, high=np.inf, shape=(self.num_skus, self.num_locations), dtype=np.float32)  # Track per location\n",
    "        })\n",
    "        \n",
    "        # Create sorted mappings for SKU and location indices\n",
    "        self.sku_id_map = {sku: idx for idx, sku in enumerate(sorted(df_items['skuid'].unique()))}\n",
    "        self.location_id_map = {loc: idx for idx, loc in enumerate(sorted(df_locations['slid'].unique()))}\n",
    "\n",
    "        # Initialize environment state\n",
    "        self.state = None\n",
    "        self.current_step = 0\n",
    "        self.current_step_year = None\n",
    "        self.current_step_week = None\n",
    "        \n",
    "        # Extract unique (year, week) pairs and sort them\n",
    "        self.unique_year_weeks = sorted(df_history[['year', 'week']].drop_duplicates().values.tolist())\n",
    "        self.max_steps = len(self.unique_year_weeks)  # Total possible timesteps in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b1cd0-a504-4697-afcd-1e17cc2878ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset(self, *, seed=None, options=None):\n",
    "    \"\"\" Resets the environment to a new random starting point in historical data. \"\"\"\n",
    "    super().reset(seed=seed)\n",
    "\n",
    "    # Select a random week in history\n",
    "    self.current_step = random.randint(0, self.max_steps - 1)\n",
    "    self.current_step_year, self.current_step_week = self.unique_year_weeks[self.current_step]\n",
    "\n",
    "    # Filter available SKUs based on stock levels at the end of the week\n",
    "    filtered_data = self.df_history[\n",
    "        (self.df_history['year'] == self.current_step_year) &\n",
    "        (self.df_history['week'] == self.current_step_week) &\n",
    "        (self.df_history['stock_end_week'] > 0)\n",
    "    ][['slid', 'skuID', 'lockWeeksRemaining', 'unique_items_count']].drop_duplicates()\n",
    "\n",
    "    # Initialize lock periods (ensures all start at 0)\n",
    "    self.lock_periods = np.zeros((self.num_skus, self.num_locations), dtype=np.int8)\n",
    "\n",
    "    # Update lock periods based on filtered SKUs\n",
    "    for _, row in filtered_data.iterrows():\n",
    "        sku_idx = self.sku_id_map.get(row['skuID'], -1)\n",
    "        loc_idx = self.location_id_map.get(row['slid'], -1)\n",
    "        if sku_idx >= 0 and loc_idx >= 0:\n",
    "            self.lock_periods[sku_idx, loc_idx] = row['lockWeeksRemaining']\n",
    "\n",
    "    # Remove unnecessary columns before passing to `_generate_observation`\n",
    "    filtered_data = filtered_data[['slid', 'skuID', 'unique_items_count']].drop_duplicates()\n",
    "\n",
    "    # Initialize state with updated filtered data\n",
    "    self.state = self._generate_observation(filtered_data)\n",
    "\n",
    "    # Return observation and empty info dictionary\n",
    "    return self.state, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8833edd-2397-40ff-b1ad-44158479c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_observation(self, filtered_data, action_matrix=None):\n",
    "    \"\"\"Generate an observation based on filtered inventory data.\"\"\"\n",
    "    \n",
    "    # Initialize observation with zeros\n",
    "    obs = {key: np.zeros((self.num_skus, self.num_locations), dtype=np.float32) \n",
    "           for key in self.observation_space.keys()}\n",
    "    \n",
    "    rolling_window_steps = 4  # Use last 4 weeks\n",
    "    \n",
    "    # Get past 4 weeks + current week\n",
    "    start_step = max(0, self.current_step - rolling_window_steps)\n",
    "    end_step = self.current_step  # Current week is included\n",
    "    rolling_year_weeks = self.unique_year_weeks[start_step:end_step + 1]  # Include current week\n",
    "    \n",
    "    if rolling_year_weeks:\n",
    "        rolling_years, rolling_weeks = zip(*rolling_year_weeks)\n",
    "    else:\n",
    "        rolling_years, rolling_weeks = np.array([], dtype=np.int16), np.array([], dtype=np.int8)  # Empty arrays if no data\n",
    "\n",
    "    # Populate observations\n",
    "    for _, row in filtered_data.iterrows():\n",
    "        sku_idx = self.sku_id_map.get(row['skuID'], -1)\n",
    "        loc_idx = self.location_id_map.get(row['slid'], -1)\n",
    "\n",
    "        if sku_idx >= 0 and loc_idx >= 0:\n",
    "            # Update current stock state based on previous step's actions\n",
    "            if action_matrix is not None:\n",
    "                obs['current_stock_state'][sku_idx, loc_idx] = action_matrix[sku_idx, loc_idx]\n",
    "            else:\n",
    "                obs['current_stock_state'][sku_idx, loc_idx] = 1  # Default if no action history available\n",
    "            \n",
    "            # Store unique items per location (static, no accumulation)\n",
    "            obs['unique_items_count'][sku_idx, loc_idx] = row['unique_items_count']\n",
    "            \n",
    "            # Add **week/year** information (seasonality feature)\n",
    "            obs['week'][sku_idx, loc_idx] = self.current_step_week\n",
    "            \n",
    "            # Select all weeks in the rolling period\n",
    "            sales_data = self.df_history[\n",
    "                (self.df_history['skuID'] == row['skuID']) & \n",
    "                (self.df_history['slid'] == row['slid']) & \n",
    "                (self.df_history['year'].isin(rolling_years)) & \n",
    "                (self.df_history['week'].isin(rolling_weeks))\n",
    "            ]\n",
    "\n",
    "            if not sales_data.empty:\n",
    "                obs['delta_stock'][sku_idx, loc_idx] = sales_data['consumption'].sum()\n",
    "                obs['delta_profit'][sku_idx, loc_idx] = (\n",
    "                    sales_data['consumption'] * \n",
    "                    (sales_data['salesPrice'] - sales_data['purchasingPrice'])\n",
    "                ).mean()\n",
    "                obs['delta_margin'][sku_idx, loc_idx] = (\n",
    "                    sales_data['salesPrice'].mean() - sales_data['purchasingPrice'].mean()\n",
    "                )\n",
    "\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad1ba1-bb84-4aa4-b7ff-4bf0f7f5ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(self, action):\n",
    "    \"\"\" Perform an environment step using the given action. \"\"\"\n",
    "    \n",
    "    # **Step 1: Move to the next step first (ensures reward calculation is correct)**\n",
    "    self.current_step += 1\n",
    "    done = self.current_step >= self.max_steps\n",
    "    truncated = False  \n",
    "    if done:\n",
    "        return self.state, 0, done, truncated, {}\n",
    "\n",
    "    # **Step 2: Convert action into (num_skus, num_locations) matrix**\n",
    "    action_matrix = action.reshape((self.num_skus, self.num_locations))\n",
    "\n",
    "    # **Step 3: Apply inventory constraints (locks, permanent items)**\n",
    "    newly_added_mask = (action_matrix == 1) & (self.state['current_stock_state'] == 0)\n",
    "\n",
    "    if np.any(newly_added_mask):\n",
    "        # Assign 12-week lock period for newly added SKUs\n",
    "        start_step = self.current_step\n",
    "        end_step = min(self.current_step + 12, len(self.unique_year_weeks))\n",
    "\n",
    "        for week_idx, lock_value in zip(range(start_step, end_step), reversed(range(1, end_step - start_step + 1))):\n",
    "            self.lock_periods[newly_added_mask] = lock_value  \n",
    "\n",
    "    # Ensure locked/permanent items are NOT removed\n",
    "    action_matrix[self.lock_periods > 0] = 1  \n",
    "    important_item_mask = self.df_items['isGenerateFlow'].fillna(0).values == 1  \n",
    "    action_matrix[important_item_mask, :] = 1  \n",
    "\n",
    "    # **Step 4: Compute reward for the previous step's action**\n",
    "    reward = self._calculate_profit(action_matrix)\n",
    "\n",
    "    # **Step 5: Reduce lock periods (items get closer to being removable)**\n",
    "    self.lock_periods = np.maximum(self.lock_periods - 1, 0)\n",
    "\n",
    "    # **Step 6: Update the current step year & week**\n",
    "    self.current_step_year, self.current_step_week = self.unique_year_weeks[self.current_step]\n",
    "\n",
    "    # **Step 7: Filter inventory data for the new step**\n",
    "    filtered_data = self.df_history[\n",
    "        (self.df_history['year'] == self.current_step_year) &\n",
    "        (self.df_history['week'] == self.current_step_week) &\n",
    "        (self.df_history['stock_end_week'] > 0)\n",
    "    ][['slid', 'skuID', 'lockWeeksRemaining', 'unique_items_count']].drop_duplicates()\n",
    "\n",
    "    # Refresh lock status for new inventory items\n",
    "    for _, row in filtered_data.iterrows():\n",
    "        sku_idx = self.sku_id_map.get(row['skuID'], -1)\n",
    "        loc_idx = self.location_id_map.get(row['slid'], -1)\n",
    "        if sku_idx >= 0 and loc_idx >= 0:\n",
    "            self.lock_periods[sku_idx, loc_idx] = row['lockWeeksRemaining']\n",
    "\n",
    "    # Drop unnecessary columns before generating new observations\n",
    "    filtered_data = filtered_data[['slid', 'skuID', 'unique_items_count']].drop_duplicates()\n",
    "\n",
    "    # **Step 8: Generate new observation state using the updated action_matrix**\n",
    "    self.state = self._generate_observation(filtered_data, action_matrix)\n",
    "\n",
    "    return self.state, reward, done, truncated, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3473d2-3fc8-4760-aaa6-96b608aa7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_profit(self, action_matrix):\n",
    "    \"\"\" Compute the reward (profit) based on inventory decisions. \"\"\"\n",
    "    \n",
    "    # Define the rolling window for the past 4 weeks\n",
    "    rolling_window_steps = 4\n",
    "    start_step = max(0, self.current_step - rolling_window_steps)\n",
    "    end_step = self.current_step\n",
    "\n",
    "    # Extract year-week combinations for the rolling window\n",
    "    rolling_year_weeks = self.unique_year_weeks[start_step:end_step]\n",
    "    rolling_years, rolling_weeks = zip(*rolling_year_weeks) if rolling_year_weeks else ([], [])\n",
    "\n",
    "    # Filter historical data for these weeks\n",
    "    history_window = self.df_history[\n",
    "        (self.df_history['year'].isin(rolling_years)) &\n",
    "        (self.df_history['week'].isin(rolling_weeks))\n",
    "    ]\n",
    "\n",
    "    # Find active SKUs & locations from the action matrix\n",
    "    active_indices = np.argwhere(action_matrix == 1)\n",
    "    active_pairs = [(self.df_items['skuid'].iloc[sku_idx], self.df_locations['slid'].iloc[loc_idx]) \n",
    "                    for sku_idx, loc_idx in active_indices]\n",
    "\n",
    "    # Filter data for active SKU-location pairs\n",
    "    active_data = history_window[history_window[['skuID', 'slid']].apply(tuple, axis=1).isin(active_pairs)].copy()\n",
    "\n",
    "    # Find items sold in different locations (excluding active pairs)\n",
    "    active_skus = list(set([sku for sku, _ in active_pairs]))\n",
    "    items_sold_elsewhere = history_window[\n",
    "        (history_window['skuID'].isin(active_skus)) &\n",
    "        (~history_window[['skuID', 'slid']].apply(tuple, axis=1).isin(active_pairs))\n",
    "    ].copy()\n",
    "\n",
    "    # Compute mean profit for SKUs sold in other locations\n",
    "    items_sold_elsewhere['sku_profit'] = (\n",
    "        items_sold_elsewhere['consumption'] * (items_sold_elsewhere['salesPrice'] - items_sold_elsewhere['purchasingPrice'])\n",
    "    )\n",
    "    mean_profit_elsewhere = items_sold_elsewhere['sku_profit'].mean()\n",
    "\n",
    "    # Initialize profit-related values\n",
    "    total_profit, delta_profit, delta_sales, avg_past_profit = 0, 0, 0, 0\n",
    "    unsold_penalty, inventory_penalty = 0, 0  \n",
    "\n",
    "    if not active_data.empty:\n",
    "        # Compute markup & profit per SKU\n",
    "        active_data['markup'] = active_data['salesPrice'] - active_data['purchasingPrice']\n",
    "        active_data['sku_profit'] = active_data['consumption'] * active_data['markup']\n",
    "\n",
    "        # Compute rolling average profit per SKU-location\n",
    "        rolling_avg_profit = active_data.groupby(['skuID', 'slid'])['sku_profit'].mean()\n",
    "\n",
    "        # Compute changes in sales and profit\n",
    "        active_data['delta_sales'] = active_data.groupby(['skuID', 'slid'])['consumption'].diff().fillna(0)\n",
    "        active_data['delta_profit'] = active_data.groupby(['skuID', 'slid'])['sku_profit'].diff().fillna(0)\n",
    "\n",
    "        # Aggregate profit-related values\n",
    "        total_profit = active_data['sku_profit'].sum()\n",
    "        delta_sales = active_data['delta_sales'].sum()\n",
    "        delta_profit = active_data['delta_profit'].sum()\n",
    "        avg_past_profit = rolling_avg_profit.mean()\n",
    "\n",
    "        # Compute penalties for unsold inventory\n",
    "        lost_profit_penalty_factor = 0.05  # 5% of potential lost profit\n",
    "        stagnant_inventory_penalty = 0.02  # 2% extra penalty per unsold week\n",
    "        max_unsold_penalty = 100  # Upper limit for penalty\n",
    "\n",
    "        unsold_penalty = active_data.groupby(['skuID', 'slid']).apply(\n",
    "            lambda x: 0 if (x['consumption'].sum() > 0 or x['stock_end_week'].mean() == 0) \n",
    "            else min(\n",
    "                (lost_profit_penalty_factor * x['stock_end_week'].mean() * x['markup'].mean()) * \n",
    "                (1 + stagnant_inventory_penalty * x.shape[0]), \n",
    "                max_unsold_penalty\n",
    "            )\n",
    "        ).sum()\n",
    "\n",
    "        # Compute inventory size penalty based on `unique_items_count`\n",
    "        penalty_factor = 5  # Scaling factor for penalty\n",
    "        tolerance = 0.1  # 10% tolerance\n",
    "\n",
    "        for loc_idx in range(self.num_locations):\n",
    "            selected_items = action_matrix[:, loc_idx].sum()\n",
    "            expected_count = self.state['unique_items_count'][:, loc_idx].sum()  \n",
    "\n",
    "            if expected_count > 0:  # Avoid division by zero\n",
    "                deviation = abs(selected_items - expected_count) / expected_count\n",
    "                if deviation > tolerance:\n",
    "                    inventory_penalty += deviation * penalty_factor  # Apply penalty\n",
    "\n",
    "    # Compute final reward (profit)\n",
    "    profit = (\n",
    "        total_profit\n",
    "        + delta_profit\n",
    "        - abs(delta_sales) * 0.1  # Penalize sales drop\n",
    "        + avg_past_profit * 0.05  # Reward historical profitability\n",
    "        - unsold_penalty  # Penalize stock without consumption\n",
    "        - inventory_penalty  # Penalize inventory deviations\n",
    "        + (0 if np.isnan(mean_profit_elsewhere) else mean_profit_elsewhere)  # Add profit from other locations\n",
    "    )\n",
    "\n",
    "    return profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f74036-cba3-4801-ac06-472ebda9db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = InventoryRotationEnv(df_items, df_history, df_locations)\n",
    "print(env.observation_space)\n",
    "\n",
    "#(by default, PPO uses a batch size of 2048 timesteps per update)\n",
    "#tensorboard --logdir=./ppo_tensorboard/    tensorboard --logdir=logs\n",
    "model = PPO('MultiInputPolicy', env, batch_size=128, n_steps=512, verbose=1, tensorboard_log=\"./logs/\") # With default hyperparameters PPO, default batch size is 32\n",
    "\"\"\"model = DQN(  \n",
    "    'MlpPolicy',\n",
    "    env,\n",
    "    learning_rate=0.0005,\n",
    "    buffer_size=50000,\n",
    "    batch_size=64,\n",
    "    gamma=0.99,\n",
    "    exploration_fraction=0.1,\n",
    "    exploration_final_eps=0.02,\n",
    "    target_update_interval=1000,\n",
    "    verbose=1\n",
    ")\"\"\"\n",
    "model.learn(total_timesteps=5_00, reset_num_timesteps=False, tb_log_name='PPO')  # Is the total number of samples (env steps) to train on.\n",
    "\n",
    "# Save/Load the trained model\n",
    "#model.save(\"inventory_rotation_dien_kremas_128_dqn\")\n",
    "#model = DQN.load(\"inventory_rotation_dqn\", tensorboard_log=\"./logs/\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd4976a-8726-43f8-8f43-1559a787f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "-------------------------------------------\n",
    "| rollout/                |               |\n",
    "|    ep_len_mean          | 54.9          |\tThe average episode length in timesteps (e.g., how many steps before an episode ends).\n",
    "|    ep_rew_mean          | 6.97e+05      |\tThe average reward per episode (higher is better). Your rewards are large—check if they need normalization!\n",
    "| time/                   |               |\n",
    "|    fps                  | 1             |\tFrames per second (very slow—may need optimization).\n",
    "|    iterations           | 2             |\tNumber of policy updates so far.\n",
    "|    time_elapsed         | 546           |\tTime spent training (in seconds).\n",
    "|    total_timesteps      | 2048          |\tTotal environment steps taken so far (taken actions) n_steps*iterations.\n",
    "| train/                  |               |\n",
    "|    approx_kl            | 0.00010914914 |\tMeasures how much the new policy deviates from the old one (should be small).\n",
    "|    clip_fraction        | 0             |\tFraction of updates that were clipped (should be > 0, usually 0.1–0.3).\n",
    "|    clip_range           | 0.2           |\tThe clipping range for PPO (default: 0.2).\n",
    "|    entropy_loss         | -1.77e+03     |\tExploration vs. exploitation—higher entropy means more exploration.\n",
    "|    explained_variance   | 5.96e-08      |\tHow well the value function explains variance (should be closer to 1).\n",
    "|    learning_rate        | 0.0003        |\tThe learning rate used in training.\n",
    "|    loss                 | 1.47e+10      |\tTotal policy loss (should decrease over time).\n",
    "|    n_updates            | 30            |\tThe number of gradient updates applied to the neural network so far.\n",
    "|    policy_gradient_loss | -0.00617      |\tMeasures how much policy gradients are changing (should be small and negative).\n",
    "|    value_loss           | 3.2e+10       |\tMeasures the difference between predicted and actual rewards.\n",
    "-------------------------------------------\n",
    "Episode: \tA full sequence of steps from the start to termination (e.g., one complete inventory cycle).\n",
    "Timestep: \tA single action taken by the agent in the environment.\n",
    "n_step: \tThe number of timesteps collected before an update (batch size for PPO).\n",
    "Iteration: \tOne cycle of collecting n_step timesteps and updating the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99058c7a-2b5a-4eeb-88d5-ba81bbb4bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Numpy:\n",
    "----------------------------------\n",
    "| rollout/           |           |\n",
    "|    ep_len_mean     | 47.7      |\n",
    "|    ep_rew_mean     | -2.78e+03 |\n",
    "| time/              |           |\n",
    "|    fps             | 4         |\n",
    "|    iterations      | 1         |\n",
    "|    time_elapsed    | 117       |\n",
    "|    total_timesteps | 512       |\n",
    "----------------------------------\n",
    "Dataframe:\n",
    "---------------------------------\n",
    "| rollout/           |          |\n",
    "|    ep_len_mean     | 44.5     |\n",
    "|    ep_rew_mean     | 6.12e+05 |\n",
    "| time/              |          |\n",
    "|    fps             | 1        |\n",
    "|    iterations      | 1        |\n",
    "|    time_elapsed    | 298      |\n",
    "|    total_timesteps | 512      |\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d15b0f-12c8-4705-936f-a30e527652e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rewards:\n",
    "152.66014652014653\n",
    "317.8796296296296\n",
    "112.25535714285715\n",
    "215.52357142857144\n",
    "189.86863636363634\n",
    "171.93217391304344\n",
    "237.0790476190476\n",
    "79.33852040816326\n",
    "40.96407966101695\n",
    "56.39324811320755\n",
    "97.71670853658537\n",
    "78.59267717391303\n",
    "49.172781753246745\n",
    "63.70759652173913\n",
    "53.65741978021978\n",
    "54.4723560523446\n",
    "30.159305172413795\n",
    "34.32607542372882\n",
    "52.500909\n",
    "17.701305785123967\n",
    "16.43823025210084\n",
    "27.808721359223302\n",
    "33.19273603603604\n",
    "18.535129770992366\n",
    "30.551248201438845\n",
    "33.46037787610619\n",
    "16.70941549295775\n",
    "16.98556235521236\n",
    "27.21990440251572\n",
    "29.328689230769232\n",
    "15.952490000000001\n",
    "35.78095887850468\n",
    "35.98402353479853\n",
    "34.25624535464536\n",
    "41.97139268571428\n",
    "17.70746530612245\n",
    "70.74843543307085\n",
    "40.116223170731715\n",
    "41.31056976516634\n",
    "24.728312126245847\n",
    "110.86117879746836\n",
    "36.17067669172933\n",
    "30.053537289915965\n",
    "32.34550205479452\n",
    "39.305570942662776\n",
    "18.86539038461538\n",
    "28.105964655172414\n",
    "50.901824603174596\n",
    "40.82102487512488\n",
    "37.97891896551724\n",
    "19.087261111111115\n",
    "15.36086351020408\n",
    "13.799410000000002\n",
    "86.00157671232877\n",
    "50.63279205069124\n",
    "45.06187518796992\n",
    "69.95995571428571\n",
    "40.4267188902007\n",
    "45.65917895752896\n",
    "87.66577348484849\n",
    "102.78078347107439\n",
    "37.14156229508197\n",
    "59.480953703703705\n",
    "50.14444966442953\n",
    "18.834866911764703\n",
    "18.01388474576271\n",
    "78.48724341085273\n",
    "29.03997911164466\n",
    "63.280750000000005\n",
    "40.20862016806722\n",
    "56.18068983050846\n",
    "23.303794736842104\n",
    "33.96447450980392\n",
    "96.92913664122138\n",
    "36.862581203007515\n",
    "42.506973076923074\n",
    "64.38074583761563\n",
    "18.206317333333335\n",
    "55.565354128440354\n",
    "87.08721341463415\n",
    "29.178195614035083\n",
    "88.24345609756097\n",
    "32.380883179723504\n",
    "16.283656521739132\n",
    "40.30242583333333\n",
    "59.19365642256903\n",
    "63.236048\n",
    "36.91558455598455\n",
    "36.701528405315614\n",
    "82.62635780075188\n",
    "mean_profit_diff_locations = nan\n",
    "total_profit = 0.0\n",
    "delta_profit = 0.0\n",
    "delta_sales = 0.0\n",
    "avg_past_profit = 0.0\n",
    "penalty = 0.9247449040412903\n",
    "unsold_penalty = 1219.7554933333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731cebbd-ab57-479b-bf18-d05b7024f8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
