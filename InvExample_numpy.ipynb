{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed0f1c8-a323-4b58-b5e3-6169275dfbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## InventoryRotationEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "572edc1e-39a4-4128-b4dc-21b08bfd93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a7c3f07-2dbd-4fec-8494-4348358277a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    1. DATA SELECTION\n",
    "\"\"\"\n",
    "# Path to the data (folders)\n",
    "path = ['C:/Users/Win-10/Documents/Python Scripts/ku']\n",
    "\n",
    "frames = []\n",
    "for p in path:\n",
    "    all_files = glob.glob(p + \"/history_*.csv\")\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, header=0, sep=',', index_col=None, low_memory=False)\n",
    "        frames.append(df)\n",
    "\n",
    "df_history = pd.concat(frames)\n",
    "\n",
    "df_items = pd.read_csv(p + \"/skus.csv\", header=0, sep=',', index_col=None, low_memory=False)\n",
    "df_locations = pd.read_csv(p + \"/locations.csv\", header=0, sep=',', index_col=None, low_memory=False)\n",
    "df_promotions = pd.read_csv(p + \"/promotions.csv\", header=0, sep=',', index_col=None, low_memory=False)\n",
    "\n",
    "# Remove temp variables from workspace\n",
    "del path, all_files, frames, filename, p, df\n",
    "    \n",
    "# Step 1: Filter df_items by multiple skuName values\n",
    "sku_names_to_filter = ['Dieninis kremas'] # ['Kūno apsauginis kremas','Lūpų dažai','Parfumuotas vanduo (EDP)','Kreminė pudra','Dieninis kremas','Lūpų blizgesiai','Akių šešėliai mono 1sp.','Tualetinis vanduo (EDT)']  # Example skuNames to filter by\n",
    "df_items = df_items[df_items['categoryGroup'].isin(sku_names_to_filter)]\n",
    "\n",
    "# Step 2: Filter df_history by the skuid values of the filtered df_items\n",
    "df_history = df_history[df_history['skuID'].isin(df_items['skuid'])]\n",
    "\n",
    "# Step 3: Filter data by the locations\n",
    "df_locations = df_locations[df_locations['slid'].isin([262,238])]\n",
    "df_history = df_history[df_history['slid'].isin([262,238])]\n",
    "df_history = df_history[(df_history['atSiteQnt'] > 0) | (df_history['consumption'] > 0)]\n",
    "\n",
    "# Set in chronological order\n",
    "df_history['updateDate'] = pd.to_datetime(df_history['updateDate'])\n",
    "df_history = df_history.sort_values(by='updateDate').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "009fdefa-13ed-483e-b230-c850a2c7f044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71918, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebc1820b-4a97-4d49-b3ad-433936e3be31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slid</th>\n",
       "      <th>skuID</th>\n",
       "      <th>updateDate</th>\n",
       "      <th>atSiteQnt</th>\n",
       "      <th>consumption</th>\n",
       "      <th>purchasingPrice</th>\n",
       "      <th>salesPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>71918.000000</td>\n",
       "      <td>71918.000000</td>\n",
       "      <td>71918</td>\n",
       "      <td>71918.000000</td>\n",
       "      <td>71918.000000</td>\n",
       "      <td>71918.000000</td>\n",
       "      <td>71918.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>254.999694</td>\n",
       "      <td>30499.587892</td>\n",
       "      <td>2024-01-03 07:59:24.359408896</td>\n",
       "      <td>123.851289</td>\n",
       "      <td>0.700159</td>\n",
       "      <td>25.338845</td>\n",
       "      <td>53.140266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>238.000000</td>\n",
       "      <td>533.000000</td>\n",
       "      <td>2022-09-27 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>238.000000</td>\n",
       "      <td>23743.000000</td>\n",
       "      <td>2023-09-06 00:00:00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.560000</td>\n",
       "      <td>23.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>262.000000</td>\n",
       "      <td>33030.000000</td>\n",
       "      <td>2024-01-12 00:00:00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.020000</td>\n",
       "      <td>43.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>262.000000</td>\n",
       "      <td>38118.000000</td>\n",
       "      <td>2024-05-24 00:00:00</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.305000</td>\n",
       "      <td>74.380200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>262.000000</td>\n",
       "      <td>54142.000000</td>\n",
       "      <td>2024-10-02 00:00:00</td>\n",
       "      <td>13656.000000</td>\n",
       "      <td>1415.000000</td>\n",
       "      <td>284.711000</td>\n",
       "      <td>438.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.908928</td>\n",
       "      <td>12209.926220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>731.927536</td>\n",
       "      <td>9.800807</td>\n",
       "      <td>21.292089</td>\n",
       "      <td>36.930782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               slid         skuID                     updateDate   \n",
       "count  71918.000000  71918.000000                          71918  \\\n",
       "mean     254.999694  30499.587892  2024-01-03 07:59:24.359408896   \n",
       "min      238.000000    533.000000            2022-09-27 00:00:00   \n",
       "25%      238.000000  23743.000000            2023-09-06 00:00:00   \n",
       "50%      262.000000  33030.000000            2024-01-12 00:00:00   \n",
       "75%      262.000000  38118.000000            2024-05-24 00:00:00   \n",
       "max      262.000000  54142.000000            2024-10-02 00:00:00   \n",
       "std       10.908928  12209.926220                            NaN   \n",
       "\n",
       "          atSiteQnt   consumption  purchasingPrice    salesPrice  \n",
       "count  71918.000000  71918.000000     71918.000000  71918.000000  \n",
       "mean     123.851289      0.700159        25.338845     53.140266  \n",
       "min        0.000000      0.000000         0.010000      0.000100  \n",
       "25%        2.000000      0.000000         7.560000     23.950000  \n",
       "50%        2.000000      0.000000        21.020000     43.760300  \n",
       "75%       10.000000      0.000000        35.305000     74.380200  \n",
       "max    13656.000000   1415.000000       284.711000    438.016500  \n",
       "std      731.927536      9.800807        21.292089     36.930782  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history.describe()  # 71_918 -> 10_584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58b54e9f-e0d5-4529-bc82-f844e52c1ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71918 entries, 0 to 71917\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   slid             71918 non-null  int64         \n",
      " 1   skuID            71918 non-null  int64         \n",
      " 2   updateDate       71918 non-null  datetime64[ns]\n",
      " 3   atSiteQnt        71918 non-null  float64       \n",
      " 4   consumption      71918 non-null  float64       \n",
      " 5   purchasingPrice  71918 non-null  float64       \n",
      " 6   salesPrice       71918 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(2)\n",
      "memory usage: 3.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_history.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c4ffaa2-8a29-4f32-a123-154794644267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slid</th>\n",
       "      <th>skuID</th>\n",
       "      <th>updateDate</th>\n",
       "      <th>atSiteQnt</th>\n",
       "      <th>consumption</th>\n",
       "      <th>purchasingPrice</th>\n",
       "      <th>salesPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33881</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34038</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34180</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34307</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34425</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       slid  skuID updateDate  atSiteQnt  consumption  purchasingPrice   \n",
       "33881   262  48722 2023-12-29       42.0          0.0             3.96  \\\n",
       "34038   262  48722 2023-12-30       42.0          0.0             3.96   \n",
       "34180   262  48722 2023-12-31       42.0          0.0             3.96   \n",
       "34307   262  48722 2024-01-01       42.0          0.0             3.96   \n",
       "34425   262  48722 2024-01-02       42.0          0.0             3.96   \n",
       "\n",
       "       salesPrice  \n",
       "33881     20.6198  \n",
       "34038     20.6198  \n",
       "34180     20.6198  \n",
       "34307     20.6198  \n",
       "34425     20.6198  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df_history[df_history['skuID'] == 48722]\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b70ef041-e6c9-452d-b3de-799ba28ecc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = temp.copy()\n",
    "\n",
    "# Convert updateDate to datetime and sort by time\n",
    "df['updateDate'] = pd.to_datetime(df['updateDate'])\n",
    "df = df.sort_values(by='updateDate').reset_index(drop=True)\n",
    "\n",
    "# Extract year and week number\n",
    "df['year'] = df['updateDate'].dt.year\n",
    "df['week'] = df['updateDate'].dt.isocalendar().week\n",
    "\n",
    "# Sort data by date to get the correct start and end of the week\n",
    "df = df.sort_values(by=['slid', 'skuID', 'year', 'week', 'updateDate'])\n",
    "\n",
    "# Group by location, SKU, year, and week\n",
    "weekly_summary = df.groupby(['slid', 'skuID', 'year', 'week']).agg({\n",
    "    'consumption': 'sum',                         # Total weekly consumption\n",
    "    'purchasingPrice': 'mean',                    # Average purchasing price\n",
    "    'salesPrice': 'mean',                         # Average sales price\n",
    "    #'isNewItem': 'max'                            # If any day has True, week should be True\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "# Step 1: Compute absolute week number (ensuring correct weekly progression)\n",
    "weekly_summary = weekly_summary.sort_values(by=['slid', 'skuID', 'year', 'week']).reset_index(drop=True)\n",
    "weekly_summary['absolute_week'] = (weekly_summary['year'] - weekly_summary['year'].min()) * 52 + weekly_summary['week']\n",
    "# Step 2: Find the first absolute week an item appeared in a location\n",
    "weekly_summary['first_absolute_week'] = weekly_summary.groupby(['slid', 'skuID'])['absolute_week'].transform('min')\n",
    "# Step 3: Compute remaining lock period (12-week lock from first appearance)\n",
    "weekly_summary['lockWeeksRemaining'] = (12 - (weekly_summary['absolute_week'] - weekly_summary['first_absolute_week'])).clip(lower=0)\n",
    "# Step 4: Drop unnecessary columns if needed\n",
    "weekly_summary.drop(columns=['first_absolute_week','absolute_week'], inplace=True)\n",
    "\n",
    "\n",
    "# Get the stock at the start and end of the week\n",
    "stock_start = df.groupby(['slid', 'skuID', 'year', 'week']).first().reset_index()[['slid', 'skuID', 'year', 'week', 'atSiteQnt']]\n",
    "stock_end = df.groupby(['slid', 'skuID', 'year', 'week']).last().reset_index()[['slid', 'skuID', 'year', 'week', 'atSiteQnt']]\n",
    "\n",
    "# Rename columns for clarity\n",
    "stock_start.rename(columns={'atSiteQnt': 'stock_start_week'}, inplace=True)\n",
    "stock_end.rename(columns={'atSiteQnt': 'stock_end_week'}, inplace=True)\n",
    "\n",
    "# Merge start and end stock with the weekly summary\n",
    "weekly_summary = weekly_summary.merge(stock_start, on=['slid', 'skuID', 'year', 'week'])\n",
    "weekly_summary = weekly_summary.merge(stock_end, on=['slid', 'skuID', 'year', 'week'])\n",
    "\n",
    "temp = weekly_summary.copy()\n",
    "\n",
    "\n",
    "# Filter out rows where stock_end_week is zero\n",
    "df_non_zero_stock = temp[(temp['stock_end_week'] > 0) | (temp['consumption'] > 0)]\n",
    "\n",
    "# Group by location, year, and week to count unique skuID\n",
    "unique_items_count = df_non_zero_stock.groupby(['slid', 'year', 'week'])['skuID'].nunique().reset_index()\n",
    "unique_items_count.rename(columns={'skuID': 'unique_items_count'}, inplace=True)\n",
    "\n",
    "# Merge the unique items count with the original DataFrame\n",
    "temp = temp.merge(unique_items_count, on=['slid', 'year', 'week'], how='left')\n",
    "\n",
    "# Fill NaN values with 0 (in case there are weeks with no items)\n",
    "temp['unique_items_count'] = temp['unique_items_count'].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "del stock_start, stock_end, weekly_summary, df, df_non_zero_stock, unique_items_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da8f679b-f367-4b1c-933a-b3a97cddf5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slid</th>\n",
       "      <th>skuID</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>consumption</th>\n",
       "      <th>purchasingPrice</th>\n",
       "      <th>salesPrice</th>\n",
       "      <th>lockWeeksRemaining</th>\n",
       "      <th>stock_start_week</th>\n",
       "      <th>stock_end_week</th>\n",
       "      <th>unique_items_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2023</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "      <td>12</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "      <td>11</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "      <td>10</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "      <td>9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262</td>\n",
       "      <td>48722</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>20.6198</td>\n",
       "      <td>8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   slid  skuID  year  week  consumption  purchasingPrice  salesPrice   \n",
       "0   262  48722  2023    52          0.0             3.96     20.6198  \\\n",
       "1   262  48722  2024     1          5.0             3.96     20.6198   \n",
       "2   262  48722  2024     2          7.0             3.96     20.6198   \n",
       "3   262  48722  2024     3          6.0             3.96     20.6198   \n",
       "4   262  48722  2024     4          7.0             3.96     20.6198   \n",
       "\n",
       "   lockWeeksRemaining  stock_start_week  stock_end_week  unique_items_count  \n",
       "0                  12              42.0            42.0                   1  \n",
       "1                  11              42.0            37.0                   1  \n",
       "2                  10              32.0            31.0                   1  \n",
       "3                   9              30.0            25.0                   1  \n",
       "4                   8              15.0             8.0                   1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "929a67cf-287f-44d9-950e-07001deb8105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2023, 52],\n",
       " [2024, 1],\n",
       " [2024, 2],\n",
       " [2024, 3],\n",
       " [2024, 4],\n",
       " [2024, 5],\n",
       " [2024, 6],\n",
       " [2024, 18],\n",
       " [2024, 19],\n",
       " [2024, 20],\n",
       " [2024, 21],\n",
       " [2024, 22],\n",
       " [2024, 23],\n",
       " [2024, 24],\n",
       " [2024, 25],\n",
       " [2024, 26],\n",
       " [2024, 27],\n",
       " [2024, 28],\n",
       " [2024, 29],\n",
       " [2024, 30],\n",
       " [2024, 31],\n",
       " [2024, 32],\n",
       " [2024, 37],\n",
       " [2024, 38],\n",
       " [2024, 39],\n",
       " [2024, 40]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(temp[['year', 'week']].drop_duplicates().values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3f309-80e8-438b-8ef0-9d1d4882fa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InventoryRotationEnv(gym.Env):\n",
    "    def __init__(self, df_items, df_history, df_locations):\n",
    "        super(InventoryRotationEnv, self).__init__()\n",
    "        \n",
    "        df_history['week'] = df_history['week'].astype('int32')\n",
    "        df_history['year'] = df_history['year'].astype('int32')\n",
    "        \n",
    "        # Initialize dataframes\n",
    "        self.df_items = df_items[['skuid', 'isGenerateFlow']].fillna(0).to_numpy()\n",
    "        self.df_history = df_history[['skuID', 'slid', 'year', 'week', 'consumption', \n",
    "                                  'purchasingPrice','salesPrice', 'stock_start_week', 'stock_end_week',\n",
    "                                  'lockWeeksRemaining', 'unique_items_count']].to_numpy(dtype=np.float32)\n",
    "        self.df_locations = df_locations[['slid']].to_numpy()\n",
    "        \n",
    "        # Determine number of SKUs and locations\n",
    "        self.num_skus = self.df_items.shape[0]\n",
    "        self.num_locations = self.df_locations.shape[0]\n",
    "        \n",
    "        # Define the action space: continuous values between 0 and 1 for each SKU-location pair\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.num_skus * self.num_locations,), dtype=np.float32)\n",
    "        \n",
    "        # Define the observation space with various SKU-level features per location\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'inventory': spaces.Box(low=0, high=1, shape=(self.num_skus, self.num_locations), dtype=np.float32),\n",
    "            'salesPrice': spaces.Box(low=0, high=np.inf, shape=(self.num_skus, self.num_locations), dtype=np.float32),\n",
    "            'purchasingPrice': spaces.Box(low=0, high=np.inf, shape=(self.num_skus, self.num_locations), dtype=np.float32),\n",
    "            'delta_margin': spaces.Box(low=-np.inf, high=np.inf, shape=(self.num_skus, self.num_locations), dtype=np.float32),\n",
    "            'delta_stock': spaces.Box(low=-np.inf, high=np.inf, shape=(self.num_skus, self.num_locations), dtype=np.float32),\n",
    "            'delta_profit': spaces.Box(low=-np.inf, high=np.inf, shape=(self.num_skus, self.num_locations), dtype=np.float32),\n",
    "            'lockWeeksRemaining': spaces.Box(low=0, high=np.inf, shape=(self.num_skus, self.num_locations), dtype=np.float32),\n",
    "            'week': spaces.Box(low=1, high=53, shape=(self.num_skus, self.num_locations), dtype=np.int16),\n",
    "        })\n",
    "        \n",
    "        # Create mappings for SKUs and locations\n",
    "        self.sku_id_map = {sku: idx for idx, sku in enumerate(np.sort(self.df_items[:, 0]))}\n",
    "        self.location_id_map = {loc: idx for idx, loc in enumerate(np.sort(self.df_locations[:, 0]))}\n",
    "        \n",
    "        # Initialize state and time tracking variables\n",
    "        self.state = None\n",
    "        self.current_step = 0\n",
    "        self.current_step_year = None\n",
    "        self.current_step_week = None\n",
    "        \n",
    "        # Extract and sort unique (year, week) combinations for time steps\n",
    "        self.unique_year_weeks = np.unique(self.df_history[:, [2, 3]], axis=0)  # Columns for 'year' and 'week'\n",
    "        self.max_steps = len(self.unique_year_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b1cd0-a504-4697-afcd-1e17cc2878ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset(self, *, seed=None, options=None):\n",
    "        \"\"\"Resets the environment to a new random starting point in historical data.\"\"\"\n",
    "        super().reset(seed=seed)\n",
    "    \n",
    "        # Step 1: Select a random step in history\n",
    "        self.current_step = np.random.randint(0, self.max_steps)\n",
    "        self.current_step_year, self.current_step_week = self.unique_year_weeks[self.current_step]\n",
    "    \n",
    "        # Step 2: Initialize the observation dictionary\n",
    "        obs = {key: np.zeros((self.num_skus, self.num_locations), dtype=np.float32)\n",
    "               for key in self.observation_space.keys()}\n",
    "        \n",
    "        # Step 3: Filter current week's data from the numpy array\n",
    "        current_week_mask = (self.df_history[:, 2] == self.current_step_year) & (self.df_history[:, 3] == self.current_step_week)\n",
    "        current_week_data = self.df_history[current_week_mask]\n",
    "    \n",
    "        # Step 4: Populate the inventory based on stock_start_week > 0\n",
    "        for row in current_week_data:\n",
    "            sku_id, loc_id = int(row[0]), int(row[1])\n",
    "            stock_start_week = row[7]  # stock_start_week column\n",
    "    \n",
    "            sku_idx = self.sku_id_map.get(sku_id, -1)\n",
    "            loc_idx = self.location_id_map.get(loc_id, -1)\n",
    "    \n",
    "            if sku_idx >= 0 and loc_idx >= 0:\n",
    "                if stock_start_week > 0:\n",
    "                    obs['inventory'][sku_idx, loc_idx] = 1  # Mark as in stock\n",
    "    \n",
    "                # Store prices and lock periods in observation\n",
    "                obs['salesPrice'][sku_idx, loc_idx] = row[6]  # salesPrice\n",
    "                obs['purchasingPrice'][sku_idx, loc_idx] = row[5]  # purchasingPrice\n",
    "                obs['week'][sku_idx, loc_idx] = self.current_step_week\n",
    "                obs['lockWeeksRemaining'][sku_idx, loc_idx] = row[9]  # lockWeeksRemaining\n",
    "    \n",
    "        # Step 5: Rolling 4-week window to calculate delta features\n",
    "        rolling_window_steps = 4\n",
    "        start_step = max(0, self.current_step - rolling_window_steps)\n",
    "        rolling_year_weeks = self.unique_year_weeks[start_step:self.current_step + 1]  # Include current week\n",
    "    \n",
    "        if rolling_year_weeks.size > 0:\n",
    "            rolling_mask = np.isin(self.df_history[:, [2, 3]], rolling_year_weeks).all(axis=1)\n",
    "            rolling_data = self.df_history[rolling_mask]\n",
    "    \n",
    "            # Step 6: Calculate delta features for each SKU-location pair\n",
    "            for row in rolling_data:\n",
    "                sku_id, loc_id = int(row[0]), int(row[1])\n",
    "                consumption = row[4]\n",
    "                purchasing_price = row[5]\n",
    "                sales_price = row[6]\n",
    "    \n",
    "                sku_idx = self.sku_id_map.get(sku_id, -1)\n",
    "                loc_idx = self.location_id_map.get(loc_id, -1)\n",
    "    \n",
    "                if sku_idx >= 0 and loc_idx >= 0:\n",
    "                    obs['delta_stock'][sku_idx, loc_idx] += consumption\n",
    "                    obs['delta_profit'][sku_idx, loc_idx] += consumption * (sales_price - purchasing_price)\n",
    "                    obs['delta_margin'][sku_idx, loc_idx] += (sales_price - purchasing_price)\n",
    "    \n",
    "        # Step 7: Finalize state\n",
    "        self.state = obs\n",
    "    \n",
    "        return self.state, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8833edd-2397-40ff-b1ad-44158479c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(self, action):\n",
    "        \"\"\" Perform an environment step using the given action. \"\"\"\n",
    "    \n",
    "        # **Step 0: Move to the next time step first (ensures reward calculation is correct)**\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= self.max_steps\n",
    "        truncated = False  \n",
    "        if done:\n",
    "            return self.state, 0, done, truncated, {}\n",
    "        \n",
    "        \"\"\" Threshold or Top-N Approach \"\"\"\n",
    "        # Step 1: Convert action into (num_skus, num_locations) probabilities\n",
    "        action_probs = action.reshape((self.num_skus, self.num_locations))\n",
    "    \n",
    "        # Step 2: Apply dynamic subset size per location\n",
    "        current_inventory_per_location = np.sum(self.state['inventory'] == 1, axis=0)\n",
    "        action_matrix = np.zeros_like(action_probs, dtype=np.int8)\n",
    "    \n",
    "        for loc_idx in range(self.num_locations):\n",
    "            subset_size = current_inventory_per_location[loc_idx]\n",
    "    \n",
    "            # Get probabilities for the current location\n",
    "            loc_probs = action_probs[:, loc_idx]\n",
    "    \n",
    "            # Select top SKUs based on probabilities\n",
    "            top_indices = np.argsort(loc_probs)[-subset_size:]\n",
    "            action_matrix[top_indices, loc_idx] = 1\n",
    "        \n",
    "        # action_matrix = (action >= 0.5).astype(np.int8).reshape((self.num_skus, self.num_locations))\n",
    "        \"\"\" Threshold or Top-N Approach \"\"\"\n",
    "    \n",
    "        # **Step 3: Apply inventory constraints (locks, permanent items)**    \n",
    "        # Identify newly added items (previously 0, now suggested as 1)\n",
    "        newly_added_mask = (action_matrix == 1) & (self.state['inventory'] == 0)\n",
    "        \n",
    "        # Identify items suggested for removal (previously 1, now suggested as 0)\n",
    "        suggested_removal_mask = (action_matrix == 0) & (self.state['inventory'] == 1)\n",
    "    \n",
    "        # **Lock newly added items for 12 weeks**\n",
    "        if np.any(newly_added_mask):\n",
    "            self.state['lockWeeksRemaining'][newly_added_mask] = 12  # Lock for 12 weeks\n",
    "    \n",
    "        # **Ensure locked or permanent items are NOT removed**\n",
    "        # Keep items locked by setting them back to 1 in the action matrix\n",
    "        action_matrix[self.state['lockWeeksRemaining'] > 0] = 1\n",
    "    \n",
    "        # Keep important items (marked by isGenerateFlow == 1)\n",
    "        important_item_mask = self.df_items[:, 1] == 1  # Assuming 'isGenerateFlow' is the second column\n",
    "        action_matrix[important_item_mask, :] = 1  \n",
    "    \n",
    "        # **Allow removal only if lock period has expired**\n",
    "        removable_items_mask = suggested_removal_mask & (self.state['lockWeeksRemaining'] == 0)\n",
    "        action_matrix[removable_items_mask] = 0  # Remove items if lock expired\n",
    "    \n",
    "        # **Step 4: Compute reward based on the current action**\n",
    "        reward = self._calculate_profit(action_matrix)  # Temporarily set reward to 0; we'll update the reward calculation later.\n",
    "        #print(reward)\n",
    "        # **Step 5: Decrease lock periods (moving towards being removable)**\n",
    "        self.state['lockWeeksRemaining'] = np.maximum(self.state['lockWeeksRemaining'] - 1, 0)\n",
    "    \n",
    "        # **Step 6: Update year and week for the current step**\n",
    "        self.current_step_year, self.current_step_week = self.unique_year_weeks[self.current_step]\n",
    "    \n",
    "        # **Step 7: Update observation directly based on the new action_matrix**\n",
    "        self._update_observation(action_matrix)\n",
    "    \n",
    "        return self.state, reward, done, truncated, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad1ba1-bb84-4aa4-b7ff-4bf0f7f5ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_observation(self, action_matrix):\n",
    "        \"\"\"Update the observation based on the current action and historical data.\"\"\"\n",
    "    \n",
    "        # Step 1: Update the current stock state based on the action\n",
    "        self.state['inventory'] = action_matrix\n",
    "    \n",
    "        # Step 2: Set the current week\n",
    "        self.state['week'][:] = self.current_step_week\n",
    "    \n",
    "        # Step 3: Filter historical data for the current week using numpy\n",
    "        current_week_data = self.df_history[\n",
    "            (self.df_history[:, 2] == self.current_step_year) &  # year\n",
    "            (self.df_history[:, 3] == self.current_step_week)    # week\n",
    "        ]\n",
    "    \n",
    "        # Step 4: Iterate through SKUs and locations to update observation features\n",
    "        for sku_idx in range(self.num_skus):\n",
    "            sku_id = self.df_items[sku_idx, 0]  # SKU ID from df_items\n",
    "    \n",
    "            for loc_idx in range(self.num_locations):\n",
    "                loc_id = self.df_locations[loc_idx, 0]  # Location ID from df_locations\n",
    "    \n",
    "                # Check if this SKU-location is active (inventory action keeps it)\n",
    "                if action_matrix[sku_idx, loc_idx] == 1:\n",
    "                    # Filter data for the specific SKU-location pair in the current week\n",
    "                    sku_loc_data = current_week_data[\n",
    "                        (current_week_data[:, 0] == sku_id) &  # skuID\n",
    "                        (current_week_data[:, 1] == loc_id)    # slid\n",
    "                    ]\n",
    "    \n",
    "                    if sku_loc_data.size > 0:\n",
    "                        # Update sales and purchasing prices (average in case of multiple entries)\n",
    "                        self.state['salesPrice'][sku_idx, loc_idx] = sku_loc_data[:, 6].mean()  # salesPrice\n",
    "                        self.state['purchasingPrice'][sku_idx, loc_idx] = sku_loc_data[:, 5].mean()  # purchasingPrice\n",
    "                \n",
    "                        # Accumulate delta features over time\n",
    "                        # Delta stock: total consumption in the current week\n",
    "                        self.state['delta_stock'][sku_idx, loc_idx] += sku_loc_data[:, 4].sum()  # consumption\n",
    "                    \n",
    "                        # Delta profit: (consumption * (salesPrice - purchasingPrice))\n",
    "                        profit_per_unit = (sku_loc_data[:, 6] - sku_loc_data[:, 5])  # salesPrice - purchasingPrice\n",
    "                        total_profit = (sku_loc_data[:, 4] * profit_per_unit).sum()\n",
    "                        self.state['delta_profit'][sku_idx, loc_idx] += total_profit\n",
    "                    \n",
    "                        # Delta margin: average difference between salesPrice and purchasingPrice\n",
    "                        self.state['delta_margin'][sku_idx, loc_idx] += profit_per_unit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3473d2-3fc8-4760-aaa6-96b608aa7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_profit(self, action_matrix):\n",
    "        \"\"\"Compute the reward (profit) based on the state after applying the action.\"\"\"\n",
    "        total_profit = 0\n",
    "        unsold_penalty = 0\n",
    "        sold_elsewhere_bonus = 0\n",
    "        high_sales_bonus = 0  # Bonus for selling high quantities\n",
    "    \n",
    "        # Step 1: Identify active SKU-location pairs from action\n",
    "        active_indices = np.argwhere(action_matrix == 1)  # Where action suggests to keep items\n",
    "        \n",
    "        for sku_idx, loc_idx in active_indices:\n",
    "            # Access state variables\n",
    "            consumption = self.state['delta_stock'][sku_idx, loc_idx]  # Total consumption\n",
    "            sales_price = self.state['salesPrice'][sku_idx, loc_idx]\n",
    "            purchase_price = self.state['purchasingPrice'][sku_idx, loc_idx]\n",
    "            stock_end_week = self._get_stock_end_week(sku_idx, loc_idx)  # Retrieve from history or state\n",
    "    \n",
    "            # Step 2: Calculate profit for the sold items\n",
    "            profit = consumption * (sales_price - purchase_price)\n",
    "            total_profit += profit\n",
    "    \n",
    "            # Step 3: Apply unsold penalty\n",
    "            if stock_end_week > 0:\n",
    "                # Potential lost profit if we didn't sell remaining stock\n",
    "                potential_unsold_profit = stock_end_week * (sales_price - purchase_price)\n",
    "                penalty = potential_unsold_profit * 0.1  # Apply 10% penalty to reflect partial loss\n",
    "                unsold_penalty += penalty\n",
    "    \n",
    "            # Step 4: Reward if items sold elsewhere\n",
    "            sold_elsewhere_qty = self._get_sold_elsewhere_quantity(sku_idx, loc_idx)\n",
    "            sold_elsewhere_bonus += sold_elsewhere_qty * 0.1  # Reward 10% for sales elsewhere\n",
    "            \n",
    "            # **Step 5: Reward for high sales volume (regardless of profit)**\n",
    "            high_sales_bonus += consumption * 0.05  # Reward based on quantity sold\n",
    "            \n",
    "        # Dynamic weights\n",
    "        profit_weight = 1.0\n",
    "        unsold_penalty_weight = 1.0\n",
    "        sales_volume_weight = 1.0\n",
    "        diversification_bonus_weight = 1.0\n",
    "    \n",
    "        # Final reward calculation\n",
    "        reward = (\n",
    "            total_profit * profit_weight                            # Profit from sold items\n",
    "            - unsold_penalty * unsold_penalty_weight                # Penalty for unsold inventory\n",
    "            + sold_elsewhere_bonus * diversification_bonus_weight   # Bonus for selling in other locations\n",
    "            + high_sales_bonus * sales_volume_weight                # Bonus for high sales volume\n",
    "        )\n",
    "    \n",
    "        return reward\n",
    "\n",
    "    def _get_stock_end_week(self, sku_idx, loc_idx):\n",
    "        \"\"\"Retrieve the stock at the end of the week from historical data.\"\"\"\n",
    "        sku_id = self.df_items[sku_idx, 0]\n",
    "        loc_id = self.df_locations[loc_idx, 0]\n",
    "    \n",
    "        # Filter historical data for current step\n",
    "        current_week_data = self.df_history[\n",
    "            (self.df_history[:, 0] == sku_id) &  # skuID\n",
    "            (self.df_history[:, 1] == loc_id) &  # slid\n",
    "            (self.df_history[:, 2] == self.current_step_year) &\n",
    "            (self.df_history[:, 3] == self.current_step_week)\n",
    "        ]\n",
    "    \n",
    "        if current_week_data.size > 0:\n",
    "            return current_week_data[0, 8]  # stock_end_week\n",
    "        return 0\n",
    "    \n",
    "    def _get_sold_elsewhere_quantity(self, sku_idx, loc_idx):\n",
    "        \"\"\"Retrieve the quantity sold in other locations for the same SKU.\"\"\"\n",
    "        sku_id = self.df_items[sku_idx, 0]\n",
    "        loc_id = self.df_locations[loc_idx, 0]\n",
    "    \n",
    "        # Filter for sales in other locations in the current week\n",
    "        sold_elsewhere = self.df_history[\n",
    "            (self.df_history[:, 0] == sku_id) &  # skuID\n",
    "            (self.df_history[:, 1] != loc_id) &  # Sold in other locations\n",
    "            (self.df_history[:, 2] == self.current_step_year) &\n",
    "            (self.df_history[:, 3] == self.current_step_week)\n",
    "        ]\n",
    "    \n",
    "        if sold_elsewhere.size > 0:\n",
    "            return sold_elsewhere[:, 4].sum()  # Total consumption elsewhere\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f74036-cba3-4801-ac06-472ebda9db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "\n",
    "env = InventoryRotationEnv(df_items, df_history, df_locations)\n",
    "print(env.observation_space)\n",
    "\n",
    "# Define stopping criteria (stop if no improvement after 5 evaluations)\n",
    "early_stop_callback = StopTrainingOnNoModelImprovement(\n",
    "    max_no_improvement_evals=5,  # Stop if no improvement after 5 evaluations\n",
    "    min_evals=3,                # Minimum number of evaluations before stopping is considered (since it evaluates at 5,000, 10,000, and 15,000)\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Define EvalCallback to evaluate and save best model\n",
    "eval_callback = EvalCallback(\n",
    "    env,\n",
    "    callback_after_eval=early_stop_callback,\n",
    "    eval_freq=5000,              # Evaluate the model every 5000 timesteps\n",
    "    best_model_save_path='./best_model',  # Path to save the best model\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#(by default, PPO uses a batch size of 2048 timesteps per update)\n",
    "#tensorboard --logdir=./ppo_tensorboard/ ARBA cd toDir THEN   tensorboard --logdir=logs\n",
    "model = PPO('MultiInputPolicy', env,\n",
    "    batch_size=1024,          # Keep batch size large\n",
    "    n_steps=512,             # Increase rollout length\n",
    "    learning_rate=2.0030562576078156e-05,     # Reduce learning rate for stability\n",
    "    gamma=0.9606577859392695,               # Increase gamma to consider more future rewards\n",
    "    gae_lambda=0.95,          # Adjust Generalized Advantage Estimation for smoother value function updates\n",
    "    ent_coef=0.05568596693799925,            # Reduce entropy coefficient to stabilize training\n",
    "    verbose=1,\n",
    "    normalize_advantage=True,\n",
    "    tensorboard_log=\"./logs/\"\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=50_000, reset_num_timesteps=False, tb_log_name='PPO', callback=eval_callback)  # Is the total number of samples (env steps) to train on.\n",
    "\n",
    "# Save/Load the trained model\n",
    "#model.save(\"inventory_rotation_dien_kremas_128_dqn\")\n",
    "#model = DQN.load(\"inventory_rotation_dqn\", tensorboard_log=\"./logs/\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd4976a-8726-43f8-8f43-1559a787f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "-------------------------------------------\n",
    "| rollout/                |               |\n",
    "|    ep_len_mean          | 54.9          |\tThe average episode length in timesteps (e.g., how many steps before an episode ends).\n",
    "|    ep_rew_mean          | 6.97e+05      |\tThe average reward per episode (higher is better). Your rewards are large—check if they need normalization!\n",
    "| time/                   |               |\n",
    "|    fps                  | 1             |\tFrames per second (very slow—may need optimization).\n",
    "|    iterations           | 2             |\tNumber of policy updates so far.\n",
    "|    time_elapsed         | 546           |\tTime spent training (in seconds).\n",
    "|    total_timesteps      | 2048          |\tTotal environment steps taken so far (taken actions) n_steps*iterations.\n",
    "| train/                  |               |\n",
    "|    approx_kl            | 0.00010914914 |\tMeasures how much the new policy deviates from the old one (should be small).\n",
    "|    clip_fraction        | 0             |\tFraction of updates that were clipped (should be > 0, usually 0.1–0.3).\n",
    "|    clip_range           | 0.2           |\tThe clipping range for PPO (default: 0.2).\n",
    "|    entropy_loss         | -1.77e+03     |\tExploration vs. exploitation—higher entropy means more exploration.\n",
    "|    explained_variance   | 5.96e-08      |\tHow well the value function explains variance (should be closer to 1).\n",
    "|    learning_rate        | 0.0003        |\tThe learning rate used in training.\n",
    "|    loss                 | 1.47e+10      |\tTotal policy loss (should decrease over time).\n",
    "|    n_updates            | 30            |\tThe number of gradient updates applied to the neural network so far.\n",
    "|    policy_gradient_loss | -0.00617      |\tMeasures how much policy gradients are changing (should be small and negative).\n",
    "|    value_loss           | 3.2e+10       |\tMeasures the difference between predicted and actual rewards.\n",
    "-------------------------------------------\n",
    "Episode: \tA full sequence of steps from the start to termination (e.g., one complete inventory cycle).\n",
    "Timestep: \tA single action taken by the agent in the environment.\n",
    "n_step: \tThe number of timesteps collected before an update (batch size for PPO).\n",
    "Iteration: \tOne cycle of collecting n_step timesteps and updating the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b313eb-f6b0-424b-aaca-cf948919425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------------------\n",
    "| rollout/           |          |\n",
    "|    ep_len_mean     | 52.6     |\n",
    "|    ep_rew_mean     | 1.17e+07 |\n",
    "| time/              |          |\n",
    "|    fps             | 7        |\n",
    "|    iterations      | 1        |\n",
    "|    time_elapsed    | 64       |\n",
    "|    total_timesteps | 45512    |\n",
    "---------------------------------\n",
    "-------------------------------------------\n",
    "| rollout/                |               |\n",
    "|    ep_len_mean          | 52.4          |\n",
    "|    ep_rew_mean          | 1.17e+07      |\n",
    "| time/                   |               |\n",
    "|    fps                  | 7             |\n",
    "|    iterations           | 2             |\n",
    "|    time_elapsed         | 128           |\n",
    "|    total_timesteps      | 46024         |\n",
    "| train/                  |               |\n",
    "|    approx_kl            | 1.1641532e-08 |\n",
    "|    clip_fraction        | 0             |\n",
    "|    clip_range           | 0.2           |\n",
    "|    entropy_loss         | -3.62e+03     |\n",
    "|    explained_variance   | 5.96e-08      |\n",
    "|    learning_rate        | 2e-05         |\n",
    "|    loss                 | 4.45e+12      |\n",
    "|    n_updates            | 880           |\n",
    "|    policy_gradient_loss | -1.89e-05     |\n",
    "|    std                  | 1             |\n",
    "|    value_loss           | 8.9e+12       |\n",
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7429d31e-ffa4-45c7-95b9-fd965f37e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Define the hyperparameter optimization function\n",
    "def optimize_ppo(trial):\n",
    "    # Define hyperparameter search space\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [512, 1024, 2048])\n",
    "    gamma = trial.suggest_uniform('gamma', 0.90, 0.99)\n",
    "    ent_coef = trial.suggest_uniform('ent_coef', 0.01, 0.1)\n",
    "    steps = trial.suggest_categorical('n_steps', [512, 1024, 2048, 4096])\n",
    "\n",
    "    # Create the environment\n",
    "    env = SubprocVecEnv([lambda: InventoryRotationEnv(df_items, df_history, df_locations) for _ in range(4)])\n",
    "\n",
    "    # Initialize PPO with suggested hyperparameters\n",
    "    model = PPO(\n",
    "        \"MultiInputPolicy\", \n",
    "        env,\n",
    "        learning_rate=learning_rate,\n",
    "        batch_size=batch_size,\n",
    "        gamma=gamma,\n",
    "        ent_coef=ent_coef,\n",
    "        n_steps=steps,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Train the model for a limited number of timesteps\n",
    "    model.learn(total_timesteps=50_000)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=5, deterministic=True)\n",
    "\n",
    "    # Return the mean reward as the objective for Optuna to maximize\n",
    "    return mean_reward\n",
    "\n",
    "# Use TPESampler for Bayesian optimization (default in Optuna)\n",
    "#sampler = optuna.samplers.TPESampler()\n",
    "# Use GridSampler for grid search\n",
    "#sampler = optuna.samplers.GridSampler(search_space)\n",
    "# Use RandomSampler for random search\n",
    "#sampler = optuna.samplers.RandomSampler()\n",
    "\n",
    "# Create the Optuna study\n",
    "study = optuna.create_study(direction='maximize')   # sampler=sampler\n",
    "study.optimize(optimize_ppo, n_trials=20)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d15b0f-12c8-4705-936f-a30e527652e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "[I 2025-02-09 15:28:42,064] Trial 1 finished with value: 10118461.741243605 and parameters: {'learning_rate': 0.00010804851334937822, 'batch_size': 512, 'gamma': 0.9805491857819207, 'ent_coef': 0.06140474468859541, 'n_steps': 512}. Best is trial 0 with value: 13127977.01602819.\n",
    "[I 2025-02-09 16:00:51,776] Trial 2 finished with value: 2913960.15687677 and parameters: {'learning_rate': 2.7703267840918958e-05, 'batch_size': 2048, 'gamma': 0.955762882575184, 'ent_coef': 0.014447912424832017, 'n_steps': 1024}. Best is trial 0 with value: 13127977.01602819.\n",
    "[I 2025-02-09 16:32:24,726] Trial 3 finished with value: 18277061.827805273 and parameters: {'learning_rate': 2.0030562576078156e-05, 'batch_size': 1024, 'gamma': 0.9606577859392695, 'ent_coef': 0.05568596693799925, 'n_steps': 512}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-09 17:08:16,387] Trial 4 finished with value: 3155552.9795123767 and parameters: {'learning_rate': 0.0007005014244145663, 'batch_size': 512, 'gamma': 0.9461849573888284, 'ent_coef': 0.03523756402106294, 'n_steps': 2048}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-09 17:48:29,556] Trial 5 finished with value: 11494704.03203483 and parameters: {'learning_rate': 4.154184255691518e-05, 'batch_size': 1024, 'gamma': 0.9259218320633796, 'ent_coef': 0.013232834429614315, 'n_steps': 4096}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-09 18:19:33,033] Trial 6 finished with value: 9789264.44600026 and parameters: {'learning_rate': 0.00021356131269591918, 'batch_size': 1024, 'gamma': 0.9694232356377241, 'ent_coef': 0.039723395972970775, 'n_steps': 1024}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-09 18:58:52,347] Trial 7 finished with value: 8834690.509522133 and parameters: {'learning_rate': 8.87631497509632e-05, 'batch_size': 1024, 'gamma': 0.9328494690731493, 'ent_coef': 0.04732696217214691, 'n_steps': 4096}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-09 19:38:16,527] Trial 8 finished with value: 7217952.033473587 and parameters: {'learning_rate': 1.628451062175235e-05, 'batch_size': 1024, 'gamma': 0.982159988616355, 'ent_coef': 0.011689457205937405, 'n_steps': 4096}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-09 20:12:45,773] Trial 9 finished with value: 2653417.2911010124 and parameters: {'learning_rate': 0.00012853721842564773, 'batch_size': 2048, 'gamma': 0.9874262367370226, 'ent_coef': 0.04641196757280243, 'n_steps': 2048}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-09 20:44:12,272] Trial 10 finished with value: 6644564.890546517 and parameters: {'learning_rate': 1.0872087991477762e-05, 'batch_size': 512, 'gamma': 0.90501519096706, 'ent_coef': 0.09244041989116991, 'n_steps': 512}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-09 21:15:26,979] Trial 11 finished with value: 15341236.574456334 and parameters: {'learning_rate': 4.031301213150346e-05, 'batch_size': 1024, 'gamma': 0.91285138422288, 'ent_coef': 0.07353452918359735, 'n_steps': 512}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-09 21:46:33,651] Trial 12 finished with value: 10905961.62867527 and parameters: {'learning_rate': 2.0942808348796655e-05, 'batch_size': 1024, 'gamma': 0.9008557404408029, 'ent_coef': 0.07336660823696259, 'n_steps': 512}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-09 22:17:46,292] Trial 13 finished with value: 12919903.453447958 and parameters: {'learning_rate': 4.58617706507172e-05, 'batch_size': 1024, 'gamma': 0.9631885681416206, 'ent_coef': 0.0807585026470101, 'n_steps': 512}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-09 22:48:54,888] Trial 14 finished with value: 9933245.678310104 and parameters: {'learning_rate': 1.233838850938475e-05, 'batch_size': 1024, 'gamma': 0.9138089004709146, 'ent_coef': 0.06410973351123077, 'n_steps': 512}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-09 23:19:50,989] Trial 15 finished with value: 11027867.461857762 and parameters: {'learning_rate': 2.9812019726707137e-05, 'batch_size': 2048, 'gamma': 0.9415836707521893, 'ent_coef': 0.0916988347931032, 'n_steps': 512}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-09 23:51:02,052] Trial 16 finished with value: 7357536.864688158 and parameters: {'learning_rate': 0.00036914429468202836, 'batch_size': 1024, 'gamma': 0.9470162323568629, 'ent_coef': 0.07200852815207352, 'n_steps': 512}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-10 00:22:03,080] Trial 17 finished with value: 4123708.2076502605 and parameters: {'learning_rate': 5.8012772078618953e-05, 'batch_size': 1024, 'gamma': 0.916429247424199, 'ent_coef': 0.030750688043332343, 'n_steps': 512}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-10 00:54:17,576] Trial 18 finished with value: 14234896.283732299 and parameters: {'learning_rate': 2.116160938034785e-05, 'batch_size': 2048, 'gamma': 0.969923252890909, 'ent_coef': 0.0558884914489124, 'n_steps': 1024}. Best is trial 3 with value: 18277061.827805273.\n",
    "[I 2025-02-10 01:28:59,399] Trial 19 finished with value: 13464429.320878655 and parameters: {'learning_rate': 7.753344968664924e-05, 'batch_size': 512, 'gamma': 0.9577830145443704, 'ent_coef': 0.08194708748617878, 'n_steps': 2048}. Best is trial 3 with value: 18277061.827805273."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731cebbd-ab57-479b-bf18-d05b7024f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Load the trained model\n",
    "model = PPO.load(\"inventory_rotation_dien_kremas_PPO_23\", tensorboard_log=\"./logs/\")\n",
    "\n",
    "env = InventoryRotationEnv(df_items, df_history, df_locations)\n",
    "obs, _ = env.reset()\n",
    "\n",
    "reward_history = []  # Track rewards for each step\n",
    "step_count = 0\n",
    "total_reward = 0\n",
    "done = False\n",
    "\n",
    "# Ensure ordered mappings for SKU and location\n",
    "sku_id_map = {sku: idx for idx, sku in enumerate(sorted(df_items['skuid'].unique()))}\n",
    "location_id_map = {loc: idx for idx, loc in enumerate(sorted(df_locations['slid'].unique()))}\n",
    "\n",
    "# Reverse lookup maps\n",
    "sku_reverse_map = {v: k for k, v in sku_id_map.items()}\n",
    "location_reverse_map = {v: k for k, v in location_id_map.items()}\n",
    "\n",
    "while not done and step_count < 10:  # Limit the test run to 10 steps\n",
    "    action, _ = model.predict(obs, deterministic=True)  # Choose action\n",
    "    prev_sku_state = obs['inventory'].copy()  # Store state before step\n",
    "    \n",
    "    # Take action in the environment\n",
    "    obs, reward, done, truncated, info = env.step(action)  \n",
    "\n",
    "    # Decode action matrix to see item movements\n",
    "    action_matrix = action.reshape((env.num_skus, env.num_locations))\n",
    "    \n",
    "    # Check how the inventory has changed after the environment processed the action\n",
    "    current_inventory = obs['inventory'].copy()\n",
    "    \n",
    "    # Count unique items per location\n",
    "    unique_items_per_location = current_inventory.sum(axis=0)  # Sum along SKUs for each location\n",
    "    \n",
    "    # Log changes in inventory\n",
    "    changes = []\n",
    "    for sku_idx in range(env.num_skus):\n",
    "        for loc_idx in range(env.num_locations):\n",
    "            sku_id = sku_reverse_map.get(sku_idx, f\"Unknown SKU {sku_idx}\")\n",
    "            loc_id = location_reverse_map.get(loc_idx, f\"Unknown Loc {loc_idx}\")\n",
    "            \n",
    "            if prev_sku_state[sku_idx, loc_idx] == 0 and current_inventory[sku_idx, loc_idx] == 1:\n",
    "                changes.append(f\"✅ Added {sku_id} to {loc_id}\")\n",
    "            elif prev_sku_state[sku_idx, loc_idx] == 1 and current_inventory[sku_idx, loc_idx] == 0:\n",
    "                changes.append(f\"❌ Removed {sku_id} from {loc_id}\")\n",
    "    \n",
    "    # Print step results\n",
    "    print(f\"\\n📌 Step {step_count + 1}: Reward={reward:.2f}, Done={done}\")\n",
    "    print(f\"   📅 Date: Year {env.current_step_year}, Week {env.current_step_week}\")\n",
    "    if changes:\n",
    "        print(\"\\n🔄 Inventory Changes:\")\n",
    "        for change in changes[0:10]:\n",
    "            print(f\"   {change}\")\n",
    "    else:\n",
    "        print(\"   ⚠ No inventory changes this step.\")\n",
    "        \n",
    "    # Print unique items per location\n",
    "    print(\"\\n📊 Unique Items Per Location:\")\n",
    "    for loc_idx, unique_count in enumerate(unique_items_per_location):\n",
    "        loc_id = location_reverse_map.get(loc_idx, f\"Unknown Loc {loc_idx}\")\n",
    "        print(f\"   📍 Location {loc_id}: {int(unique_count)} unique items in inventory.\")\n",
    "\n",
    "    # Track rewards\n",
    "    reward_history.append(reward)\n",
    "    total_reward += reward\n",
    "    step_count += 1\n",
    "\n",
    "print(f\"\\n🏆 Total Reward Over {step_count} Steps: {total_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bfe59c-103a-43d6-a364-d93da6084509",
   "metadata": {},
   "outputs": [],
   "source": [
    "❌ Removed 48963 from 238\n",
    "✅ Added 49561 to 238\n",
    "✅ Added 50429 to 262\n",
    "✅ Added 50465 to 262\n",
    "✅ Added 51181 to 262\n",
    "✅ Added 51282 to 262\n",
    "✅ Added 52338 to 238\n",
    "✅ Added 52345 to 262\n",
    "✅ Added 52557 to 262\n",
    "✅ Added 52599 to 238\n",
    "✅ Added 52607 to 262\n",
    "✅ Added 53631 to 262"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
